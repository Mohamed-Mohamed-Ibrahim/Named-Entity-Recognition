{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPORTS & CONFIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:07.031104Z",
     "iopub.status.busy": "2025-11-18T15:02:07.030837Z",
     "iopub.status.idle": "2025-11-18T15:02:07.125786Z",
     "shell.execute_reply": "2025-11-18T15:02:07.125066Z",
     "shell.execute_reply.started": "2025-11-18T15:02:07.031080Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from datasets import load_dataset\n",
    "import pickle\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device =\", DEVICE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LOAD EMBEDDINGS FROM PART 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:07.127816Z",
     "iopub.status.busy": "2025-11-18T15:02:07.127500Z",
     "iopub.status.idle": "2025-11-18T15:02:07.597019Z",
     "shell.execute_reply": "2025-11-18T15:02:07.596304Z",
     "shell.execute_reply.started": "2025-11-18T15:02:07.127797Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original vocab: 14068 Embedding dim: 100\n",
      "Final vocab with PAD/UNK: 14070\n"
     ]
    }
   ],
   "source": [
    "emb = np.load(\"/kaggle/input/custom-word2vec-output/embeddings.npy\")  \n",
    "with open(\"/kaggle/input/custom-word2vec-output/word_to_idx.pkl\", \"rb\") as f:\n",
    "    word_to_idx = pickle.load(f)\n",
    "\n",
    "orig_vocab_size, EMBED_DIM = emb.shape\n",
    "print(\"Original vocab:\", orig_vocab_size, \"Embedding dim:\", EMBED_DIM)\n",
    "\n",
    "\n",
    "PAD_ID = 0\n",
    "UNK_ID = 1\n",
    "\n",
    "new_emb = np.zeros((orig_vocab_size + 2, EMBED_DIM), dtype=np.float32)\n",
    "new_emb[2:] = emb                              \n",
    "new_emb[UNK_ID] = np.random.uniform(-0.01,0.01,EMBED_DIM)  \n",
    "\n",
    "# shift word_to_idx by +2\n",
    "new_w2i = {\"<PAD>\":0, \"<UNK>\":1}\n",
    "for w, i in word_to_idx.items():\n",
    "    new_w2i[w] = i + 2\n",
    "\n",
    "word_to_idx = new_w2i\n",
    "embedding_matrix = torch.tensor(new_emb, dtype=torch.float32)\n",
    "vocab_size = embedding_matrix.shape[0]\n",
    "\n",
    "print(\"Final vocab with PAD/UNK:\", vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA PREPARATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:07.598078Z",
     "iopub.status.busy": "2025-11-18T15:02:07.597797Z",
     "iopub.status.idle": "2025-11-18T15:02:10.461146Z",
     "shell.execute_reply": "2025-11-18T15:02:10.460364Z",
     "shell.execute_reply.started": "2025-11-18T15:02:07.598051Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9941d420c2f24eb3b2c4ac9ae73e1d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "dataset_infos.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd5ce6805a914f61ab6a084519b7cc4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/train-00000-of-00001.parquet:   0%|          | 0.00/1.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50d5d1b866ca47a9b2eee9da616dff43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/validation-00000-of-00001.parquet:   0%|          | 0.00/281k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3647759320e42f0b08ba23ef4ccdb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "data/test-00000-of-00001.parquet:   0%|          | 0.00/259k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccdeedbd8244cb8b8f775def4f1d299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/14041 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fe1c94f0cb84da5b9bfbe5d3882e758",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/3250 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e7abcdded934882ae94366bb04883c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3453 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset(\"lhoestq/conll2003\")\n",
    "\n",
    "train_split = dataset[\"train\"]\n",
    "val_split = dataset[\"validation\"]\n",
    "test_split = dataset[\"test\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WINDOW DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:10.462206Z",
     "iopub.status.busy": "2025-11-18T15:02:10.461941Z",
     "iopub.status.idle": "2025-11-18T15:02:10.468364Z",
     "shell.execute_reply": "2025-11-18T15:02:10.467706Z",
     "shell.execute_reply.started": "2025-11-18T15:02:10.462187Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class WindowNERDataset(Dataset):\n",
    "    def __init__(self, split, word_to_idx, window_size):\n",
    "        self.window_size = window_size\n",
    "        self.pad = word_to_idx[\"<PAD>\"]\n",
    "        self.unk = word_to_idx[\"<UNK>\"]\n",
    "        self.samples = []\n",
    "\n",
    "        for entry in split:\n",
    "            tokens = entry[\"tokens\"]\n",
    "            labels = entry[\"ner_tags\"]\n",
    "\n",
    "            idxs = [word_to_idx.get(t.lower(), self.unk) for t in tokens]\n",
    "\n",
    "            padded = [self.pad]*window_size + idxs + [self.pad]*window_size\n",
    "\n",
    "            for i in range(len(tokens)):\n",
    "                window = padded[i:i + 2*window_size + 1]\n",
    "                self.samples.append((window, labels[i]))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        w, y = self.samples[idx]\n",
    "        return torch.tensor(w, dtype=torch.long), torch.tensor(y, dtype=torch.long)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FEED FORWARD TAGGER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:10.469453Z",
     "iopub.status.busy": "2025-11-18T15:02:10.469204Z",
     "iopub.status.idle": "2025-11-18T15:02:10.496158Z",
     "shell.execute_reply": "2025-11-18T15:02:10.495382Z",
     "shell.execute_reply.started": "2025-11-18T15:02:10.469429Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class FFNTagger(nn.Module):\n",
    "    def __init__(self, embedding_matrix, window, hidden=256, hidden2=128, num_classes=9):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding.from_pretrained(\n",
    "            embedding_matrix,\n",
    "            freeze=True      \n",
    "        )\n",
    "\n",
    "        input_dim = (2*window + 1) * embedding_matrix.size(1)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden, hidden2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "\n",
    "            nn.Linear(hidden2, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        emb = self.embedding(x)                      # (B, window, D)\n",
    "        concat = emb.view(emb.size(0), -1)           # (B, window*D)\n",
    "        return self.ffn(concat)                      # (B, num_classes)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BUILD DATASETS & LOADERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:10.498179Z",
     "iopub.status.busy": "2025-11-18T15:02:10.497894Z",
     "iopub.status.idle": "2025-11-18T15:02:13.437322Z",
     "shell.execute_reply": "2025-11-18T15:02:13.436502Z",
     "shell.execute_reply.started": "2025-11-18T15:02:10.498163Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train samples = 203621\n",
      "Val samples   = 51362\n",
      "Test samples  = 46435\n"
     ]
    }
   ],
   "source": [
    "WINDOW = 2\n",
    "HIDDEN_DIM = 256\n",
    "NUM_CLASSES = 9\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 60        \n",
    "LR = 3e-3          \n",
    "\n",
    "train_ds = WindowNERDataset(train_split, word_to_idx, WINDOW)\n",
    "val_ds   = WindowNERDataset(val_split, word_to_idx, WINDOW)\n",
    "test_ds  = WindowNERDataset(test_split,  word_to_idx, WINDOW)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"Train samples =\", len(train_ds))\n",
    "print(\"Val samples   =\", len(val_ds))\n",
    "print(\"Test samples  =\", len(test_ds))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING & EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:13.440793Z",
     "iopub.status.busy": "2025-11-18T15:02:13.440320Z",
     "iopub.status.idle": "2025-11-18T15:02:13.446233Z",
     "shell.execute_reply": "2025-11-18T15:02:13.445457Z",
     "shell.execute_reply.started": "2025-11-18T15:02:13.440772Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, loader, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    y_true, y_pred = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "            logits = model(x)\n",
    "            loss = loss_fn(logits, y)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = logits.argmax(1)\n",
    "            y_true += y.cpu().tolist()\n",
    "            y_pred += preds.cpu().tolist()\n",
    "\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    report = classification_report(y_true, y_pred, digits=4)\n",
    "    return avg_loss, report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRAINING LOOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:02:13.448002Z",
     "iopub.status.busy": "2025-11-18T15:02:13.447097Z",
     "iopub.status.idle": "2025-11-18T15:05:06.243963Z",
     "shell.execute_reply": "2025-11-18T15:05:06.243106Z",
     "shell.execute_reply.started": "2025-11-18T15:02:13.447977Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1/60\n",
      "Train Loss = 0.4713\n",
      "Val Loss   = 0.3406\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9116    0.9949    0.9515     42759\n",
      "           1     0.8496    0.6412    0.7308      1842\n",
      "           2     0.9005    0.6924    0.7829      1307\n",
      "           3     0.6760    0.4124    0.5123      1341\n",
      "           4     0.8636    0.0253    0.0492       751\n",
      "           5     0.8373    0.6527    0.7336      1837\n",
      "           6     0.8710    0.1051    0.1875       257\n",
      "           7     0.0000    0.0000    0.0000       922\n",
      "           8     0.0000    0.0000    0.0000       346\n",
      "\n",
      "    accuracy                         0.9039     51362\n",
      "   macro avg     0.6566    0.3915    0.4386     51362\n",
      "weighted avg     0.8769    0.9039    0.8795     51362\n",
      "\n",
      " Saved best model!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2/60\n",
      "Train Loss = 0.3906\n",
      "Val Loss   = 0.3124\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9159    0.9965    0.9545     42759\n",
      "           1     0.8806    0.6688    0.7603      1842\n",
      "           2     0.9159    0.7253    0.8096      1307\n",
      "           3     0.8518    0.3729    0.5187      1341\n",
      "           4     0.8889    0.0852    0.1555       751\n",
      "           5     0.8303    0.7246    0.7738      1837\n",
      "           6     0.8824    0.2335    0.3692       257\n",
      "           7     0.9200    0.0748    0.1384       922\n",
      "           8     0.0000    0.0000    0.0000       346\n",
      "\n",
      "    accuracy                         0.9115     51362\n",
      "   macro avg     0.7873    0.4313    0.4978     51362\n",
      "weighted avg     0.9032    0.9115    0.8903     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 3/60\n",
      "Train Loss = 0.3645\n",
      "Val Loss   = 0.2854\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9263    0.9947    0.9593     42759\n",
      "           1     0.8578    0.7367    0.7926      1842\n",
      "           2     0.8838    0.8034    0.8417      1307\n",
      "           3     0.7992    0.4273    0.5569      1341\n",
      "           4     0.6771    0.2011    0.3101       751\n",
      "           5     0.8403    0.7131    0.7715      1837\n",
      "           6     0.9080    0.3074    0.4593       257\n",
      "           7     0.9455    0.0564    0.1064       922\n",
      "           8     0.9677    0.0867    0.1592       346\n",
      "\n",
      "    accuracy                         0.9177     51362\n",
      "   macro avg     0.8673    0.4808    0.5508     51362\n",
      "weighted avg     0.9132    0.9177    0.9004     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 4/60\n",
      "Train Loss = 0.3474\n",
      "Val Loss   = 0.2793\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9255    0.9960    0.9595     42759\n",
      "           1     0.8561    0.7915    0.8226      1842\n",
      "           2     0.9222    0.7613    0.8340      1307\n",
      "           3     0.8405    0.4243    0.5639      1341\n",
      "           4     0.5980    0.2397    0.3422       751\n",
      "           5     0.8803    0.7207    0.7926      1837\n",
      "           6     0.9487    0.1440    0.2500       257\n",
      "           7     0.9714    0.0369    0.0711       922\n",
      "           8     1.0000    0.0173    0.0341       346\n",
      "\n",
      "    accuracy                         0.9188     51362\n",
      "   macro avg     0.8825    0.4591    0.5189     51362\n",
      "weighted avg     0.9157    0.9188    0.9003     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 5/60\n",
      "Train Loss = 0.3384\n",
      "Val Loss   = 0.2724\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9334    0.9942    0.9628     42759\n",
      "           1     0.8320    0.7932    0.8121      1842\n",
      "           2     0.9081    0.8018    0.8517      1307\n",
      "           3     0.8746    0.4057    0.5543      1341\n",
      "           4     0.5986    0.2304    0.3327       751\n",
      "           5     0.8338    0.7648    0.7978      1837\n",
      "           6     0.9286    0.1518    0.2609       257\n",
      "           7     0.8414    0.2072    0.3325       922\n",
      "           8     0.9762    0.1185    0.2113       346\n",
      "\n",
      "    accuracy                         0.9231     51362\n",
      "   macro avg     0.8585    0.4964    0.5685     51362\n",
      "weighted avg     0.9177    0.9231    0.9089     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 6/60\n",
      "Train Loss = 0.3313\n",
      "Val Loss   = 0.2585\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9377    0.9933    0.9647     42759\n",
      "           1     0.8146    0.8442    0.8291      1842\n",
      "           2     0.8988    0.8087    0.8514      1307\n",
      "           3     0.8149    0.4564    0.5851      1341\n",
      "           4     0.7909    0.2770    0.4103       751\n",
      "           5     0.8726    0.7343    0.7975      1837\n",
      "           6     0.8455    0.3619    0.5068       257\n",
      "           7     0.8339    0.2560    0.3917       922\n",
      "           8     1.0000    0.0809    0.1497       346\n",
      "\n",
      "    accuracy                         0.9269     51362\n",
      "   macro avg     0.8676    0.5347    0.6096     51362\n",
      "weighted avg     0.9227    0.9269    0.9149     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 7/60\n",
      "Train Loss = 0.3246\n",
      "Val Loss   = 0.2549\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9414    0.9907    0.9654     42759\n",
      "           1     0.8435    0.8132    0.8281      1842\n",
      "           2     0.8623    0.8340    0.8479      1307\n",
      "           3     0.7561    0.4855    0.5913      1341\n",
      "           4     0.6711    0.3369    0.4486       751\n",
      "           5     0.8771    0.7382    0.8017      1837\n",
      "           6     0.9167    0.2996    0.4516       257\n",
      "           7     0.7717    0.3189    0.4513       922\n",
      "           8     0.9359    0.2110    0.3443       346\n",
      "\n",
      "    accuracy                         0.9278     51362\n",
      "   macro avg     0.8418    0.5587    0.6367     51362\n",
      "weighted avg     0.9216    0.9278    0.9183     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 8/60\n",
      "Train Loss = 0.3203\n",
      "Val Loss   = 0.2558\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9363    0.9942    0.9644     42759\n",
      "           1     0.8525    0.8219    0.8369      1842\n",
      "           2     0.9011    0.8156    0.8562      1307\n",
      "           3     0.8295    0.4787    0.6071      1341\n",
      "           4     0.6384    0.3103    0.4176       751\n",
      "           5     0.8835    0.7469    0.8094      1837\n",
      "           6     0.9474    0.2101    0.3439       257\n",
      "           7     0.8768    0.1931    0.3164       922\n",
      "           8     1.0000    0.1358    0.2392       346\n",
      "\n",
      "    accuracy                         0.9271     51362\n",
      "   macro avg     0.8739    0.5230    0.5990     51362\n",
      "weighted avg     0.9228    0.9271    0.9146     51362\n",
      "\n",
      "No improvement (1/6)\n",
      "\n",
      "Epoch 9/60\n",
      "Train Loss = 0.3158\n",
      "Val Loss   = 0.2533\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9383    0.9936    0.9652     42759\n",
      "           1     0.8275    0.8436    0.8355      1842\n",
      "           2     0.8997    0.8171    0.8565      1307\n",
      "           3     0.7699    0.4989    0.6054      1341\n",
      "           4     0.7156    0.3116    0.4341       751\n",
      "           5     0.9007    0.7207    0.8007      1837\n",
      "           6     0.8505    0.3541    0.5000       257\n",
      "           7     0.8592    0.1985    0.3225       922\n",
      "           8     1.0000    0.0925    0.1693       346\n",
      "\n",
      "    accuracy                         0.9275     51362\n",
      "   macro avg     0.8624    0.5367    0.6099     51362\n",
      "weighted avg     0.9229    0.9275    0.9155     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 10/60\n",
      "Train Loss = 0.3134\n",
      "Val Loss   = 0.2536\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9411    0.9924    0.9661     42759\n",
      "           1     0.8276    0.8339    0.8307      1842\n",
      "           2     0.8828    0.8125    0.8462      1307\n",
      "           3     0.7843    0.4691    0.5870      1341\n",
      "           4     0.6591    0.3888    0.4891       751\n",
      "           5     0.8778    0.7392    0.8026      1837\n",
      "           6     0.9149    0.3346    0.4900       257\n",
      "           7     0.9231    0.2082    0.3398       922\n",
      "           8     0.8632    0.2919    0.4363       346\n",
      "\n",
      "    accuracy                         0.9285     51362\n",
      "   macro avg     0.8527    0.5634    0.6431     51362\n",
      "weighted avg     0.9241    0.9285    0.9183     51362\n",
      "\n",
      "No improvement (1/6)\n",
      "\n",
      "Epoch 11/60\n",
      "Train Loss = 0.3098\n",
      "Val Loss   = 0.2494\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9446    0.9917    0.9676     42759\n",
      "           1     0.8117    0.8610    0.8356      1842\n",
      "           2     0.8814    0.8416    0.8611      1307\n",
      "           3     0.8213    0.4937    0.6167      1341\n",
      "           4     0.6995    0.3595    0.4749       751\n",
      "           5     0.8718    0.7588    0.8114      1837\n",
      "           6     0.8687    0.3346    0.4831       257\n",
      "           7     0.8852    0.2343    0.3705       922\n",
      "           8     0.8346    0.3208    0.4635       346\n",
      "\n",
      "    accuracy                         0.9313     51362\n",
      "   macro avg     0.8465    0.5773    0.6538     51362\n",
      "weighted avg     0.9266    0.9313    0.9217     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 12/60\n",
      "Train Loss = 0.2960\n",
      "Val Loss   = 0.2485\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9412    0.9924    0.9661     42759\n",
      "           1     0.8130    0.8686    0.8399      1842\n",
      "           2     0.8820    0.8294    0.8549      1307\n",
      "           3     0.8581    0.4825    0.6177      1341\n",
      "           4     0.6875    0.3662    0.4778       751\n",
      "           5     0.8795    0.7512    0.8103      1837\n",
      "           6     0.8737    0.3230    0.4716       257\n",
      "           7     0.9153    0.1876    0.3114       922\n",
      "           8     0.9863    0.2081    0.3437       346\n",
      "\n",
      "    accuracy                         0.9296     51362\n",
      "   macro avg     0.8707    0.5565    0.6326     51362\n",
      "weighted avg     0.9265    0.9296    0.9185     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 13/60\n",
      "Train Loss = 0.2908\n",
      "Val Loss   = 0.2424\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9453    0.9918    0.9680     42759\n",
      "           1     0.8346    0.8654    0.8497      1842\n",
      "           2     0.9174    0.8240    0.8682      1307\n",
      "           3     0.8101    0.5280    0.6393      1341\n",
      "           4     0.8681    0.3156    0.4629       751\n",
      "           5     0.8495    0.7806    0.8136      1837\n",
      "           6     0.7458    0.5136    0.6083       257\n",
      "           7     0.8274    0.3275    0.4693       922\n",
      "           8     1.0000    0.1127    0.2026       346\n",
      "\n",
      "    accuracy                         0.9332     51362\n",
      "   macro avg     0.8665    0.5844    0.6535     51362\n",
      "weighted avg     0.9298    0.9332    0.9238     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 14/60\n",
      "Train Loss = 0.2870\n",
      "Val Loss   = 0.2482\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9447    0.9920    0.9678     42759\n",
      "           1     0.8475    0.8447    0.8461      1842\n",
      "           2     0.9397    0.7988    0.8635      1307\n",
      "           3     0.8346    0.4929    0.6198      1341\n",
      "           4     0.7176    0.3249    0.4473       751\n",
      "           5     0.8416    0.7866    0.8132      1837\n",
      "           6     0.7754    0.4163    0.5418       257\n",
      "           7     0.7816    0.3688    0.5011       922\n",
      "           8     0.9574    0.2601    0.4091       346\n",
      "\n",
      "    accuracy                         0.9327     51362\n",
      "   macro avg     0.8489    0.5872    0.6677     51362\n",
      "weighted avg     0.9275    0.9327    0.9243     51362\n",
      "\n",
      "No improvement (1/6)\n",
      "\n",
      "Epoch 15/60\n",
      "Train Loss = 0.2853\n",
      "Val Loss   = 0.2415\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9438    0.9926    0.9676     42759\n",
      "           1     0.8170    0.8822    0.8483      1842\n",
      "           2     0.9389    0.8110    0.8703      1307\n",
      "           3     0.8434    0.4981    0.6263      1341\n",
      "           4     0.7210    0.3475    0.4690       751\n",
      "           5     0.8612    0.7839    0.8207      1837\n",
      "           6     0.9277    0.2996    0.4529       257\n",
      "           7     0.8755    0.2592    0.4000       922\n",
      "           8     0.9474    0.2601    0.4082       346\n",
      "\n",
      "    accuracy                         0.9326     51362\n",
      "   macro avg     0.8751    0.5705    0.6515     51362\n",
      "weighted avg     0.9290    0.9326    0.9228     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 16/60\n",
      "Train Loss = 0.2824\n",
      "Val Loss   = 0.2429\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9441    0.9929    0.9679     42759\n",
      "           1     0.8228    0.8773    0.8492      1842\n",
      "           2     0.9332    0.7911    0.8563      1307\n",
      "           3     0.7896    0.5093    0.6192      1341\n",
      "           4     0.8328    0.3449    0.4878       751\n",
      "           5     0.8984    0.7414    0.8124      1837\n",
      "           6     0.8137    0.5097    0.6268       257\n",
      "           7     0.8337    0.3644    0.5072       922\n",
      "           8     0.9683    0.1763    0.2983       346\n",
      "\n",
      "    accuracy                         0.9333     51362\n",
      "   macro avg     0.8707    0.5897    0.6694     51362\n",
      "weighted avg     0.9297    0.9333    0.9246     51362\n",
      "\n",
      "No improvement (1/6)\n",
      "\n",
      "Epoch 17/60\n",
      "Train Loss = 0.2794\n",
      "Val Loss   = 0.2435\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9447    0.9920    0.9678     42759\n",
      "           1     0.8069    0.8871    0.8451      1842\n",
      "           2     0.9068    0.8263    0.8647      1307\n",
      "           3     0.8007    0.5242    0.6336      1341\n",
      "           4     0.8025    0.3462    0.4837       751\n",
      "           5     0.9096    0.7289    0.8093      1837\n",
      "           6     0.8710    0.4202    0.5669       257\n",
      "           7     0.8421    0.3297    0.4739       922\n",
      "           8     0.9540    0.2399    0.3834       346\n",
      "\n",
      "    accuracy                         0.9331     51362\n",
      "   macro avg     0.8709    0.5883    0.6698     51362\n",
      "weighted avg     0.9295    0.9331    0.9245     51362\n",
      "\n",
      "No improvement (2/6)\n",
      "\n",
      "Epoch 18/60\n",
      "Train Loss = 0.2779\n",
      "Val Loss   = 0.2423\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9413    0.9934    0.9667     42759\n",
      "           1     0.8132    0.8789    0.8448      1842\n",
      "           2     0.9464    0.7972    0.8654      1307\n",
      "           3     0.7786    0.5324    0.6324      1341\n",
      "           4     0.8872    0.3036    0.4524       751\n",
      "           5     0.9068    0.7365    0.8129      1837\n",
      "           6     0.8079    0.4747    0.5980       257\n",
      "           7     0.8706    0.2918    0.4370       922\n",
      "           8     1.0000    0.0549    0.1041       346\n",
      "\n",
      "    accuracy                         0.9315     51362\n",
      "   macro avg     0.8836    0.5626    0.6349     51362\n",
      "weighted avg     0.9290    0.9315    0.9208     51362\n",
      "\n",
      "No improvement (3/6)\n",
      "\n",
      "Epoch 19/60\n",
      "Train Loss = 0.2750\n",
      "Val Loss   = 0.2421\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9505    0.9908    0.9702     42759\n",
      "           1     0.8109    0.8844    0.8460      1842\n",
      "           2     0.9112    0.8248    0.8659      1307\n",
      "           3     0.7782    0.5705    0.6583      1341\n",
      "           4     0.8137    0.3489    0.4884       751\n",
      "           5     0.8816    0.7779    0.8265      1837\n",
      "           6     0.8618    0.4125    0.5579       257\n",
      "           7     0.8558    0.3991    0.5444       922\n",
      "           8     0.8718    0.2948    0.4406       346\n",
      "\n",
      "    accuracy                         0.9366     51362\n",
      "   macro avg     0.8595    0.6115    0.6887     51362\n",
      "weighted avg     0.9328    0.9366    0.9295     51362\n",
      "\n",
      "No improvement (4/6)\n",
      "\n",
      "Epoch 20/60\n",
      "Train Loss = 0.2618\n",
      "Val Loss   = 0.2362\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9512    0.9913    0.9708     42759\n",
      "           1     0.8417    0.8779    0.8594      1842\n",
      "           2     0.8961    0.8577    0.8765      1307\n",
      "           3     0.8518    0.5570    0.6736      1341\n",
      "           4     0.7841    0.4208    0.5477       751\n",
      "           5     0.8485    0.8138    0.8308      1837\n",
      "           6     0.8897    0.4708    0.6158       257\n",
      "           7     0.8930    0.3438    0.4965       922\n",
      "           8     0.9468    0.2572    0.4045       346\n",
      "\n",
      "    accuracy                         0.9386     51362\n",
      "   macro avg     0.8781    0.6211    0.6973     51362\n",
      "weighted avg     0.9358    0.9386    0.9314     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 21/60\n",
      "Train Loss = 0.2573\n",
      "Val Loss   = 0.2409\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9497    0.9919    0.9703     42759\n",
      "           1     0.8285    0.8838    0.8553      1842\n",
      "           2     0.9262    0.8263    0.8734      1307\n",
      "           3     0.8091    0.5720    0.6702      1341\n",
      "           4     0.8070    0.4008    0.5356       751\n",
      "           5     0.8561    0.7997    0.8269      1837\n",
      "           6     0.9070    0.4553    0.6062       257\n",
      "           7     0.8986    0.3557    0.5097       922\n",
      "           8     1.0000    0.1214    0.2165       346\n",
      "\n",
      "    accuracy                         0.9373     51362\n",
      "   macro avg     0.8869    0.6008    0.6738     51362\n",
      "weighted avg     0.9348    0.9373    0.9292     51362\n",
      "\n",
      "No improvement (1/6)\n",
      "\n",
      "Epoch 22/60\n",
      "Train Loss = 0.2541\n",
      "Val Loss   = 0.2382\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9505    0.9920    0.9708     42759\n",
      "           1     0.8639    0.8616    0.8627      1842\n",
      "           2     0.9344    0.8179    0.8723      1307\n",
      "           3     0.8121    0.5899    0.6834      1341\n",
      "           4     0.8520    0.3755    0.5213       751\n",
      "           5     0.8540    0.8155    0.8343      1837\n",
      "           6     0.8535    0.5214    0.6473       257\n",
      "           7     0.8362    0.4262    0.5647       922\n",
      "           8     0.9846    0.1850    0.3114       346\n",
      "\n",
      "    accuracy                         0.9392     51362\n",
      "   macro avg     0.8824    0.6206    0.6965     51362\n",
      "weighted avg     0.9361    0.9392    0.9321     51362\n",
      "\n",
      "No improvement (2/6)\n",
      "\n",
      "Epoch 23/60\n",
      "Train Loss = 0.2531\n",
      "Val Loss   = 0.2315\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9537    0.9908    0.9719     42759\n",
      "           1     0.8201    0.8887    0.8530      1842\n",
      "           2     0.8982    0.8638    0.8807      1307\n",
      "           3     0.8208    0.5600    0.6658      1341\n",
      "           4     0.8088    0.4168    0.5501       751\n",
      "           5     0.8662    0.8035    0.8337      1837\n",
      "           6     0.8690    0.4903    0.6269       257\n",
      "           7     0.8595    0.3915    0.5380       922\n",
      "           8     0.9027    0.2948    0.4444       346\n",
      "\n",
      "    accuracy                         0.9396     51362\n",
      "   macro avg     0.8665    0.6334    0.7072     51362\n",
      "weighted avg     0.9363    0.9396    0.9331     51362\n",
      "\n",
      " Saved best model!\n",
      "\n",
      "Epoch 24/60\n",
      "Train Loss = 0.2503\n",
      "Val Loss   = 0.2348\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9531    0.9914    0.9719     42759\n",
      "           1     0.8199    0.8947    0.8557      1842\n",
      "           2     0.9169    0.8531    0.8839      1307\n",
      "           3     0.8112    0.5705    0.6699      1341\n",
      "           4     0.8393    0.4035    0.5450       751\n",
      "           5     0.8735    0.8078    0.8394      1837\n",
      "           6     0.8873    0.4903    0.6316       257\n",
      "           7     0.8759    0.4056    0.5545       922\n",
      "           8     0.9775    0.2514    0.4000       346\n",
      "\n",
      "    accuracy                         0.9402     51362\n",
      "   macro avg     0.8839    0.6298    0.7057     51362\n",
      "weighted avg     0.9377    0.9402    0.9336     51362\n",
      "\n",
      "No improvement (1/6)\n",
      "\n",
      "Epoch 25/60\n",
      "Train Loss = 0.2496\n",
      "Val Loss   = 0.2350\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9523    0.9925    0.9720     42759\n",
      "           1     0.8435    0.8806    0.8616      1842\n",
      "           2     0.9423    0.8240    0.8792      1307\n",
      "           3     0.7777    0.6025    0.6790      1341\n",
      "           4     0.8283    0.4048    0.5438       751\n",
      "           5     0.8935    0.7899    0.8385      1837\n",
      "           6     0.8986    0.4825    0.6278       257\n",
      "           7     0.8575    0.4176    0.5616       922\n",
      "           8     0.9478    0.3150    0.4729       346\n",
      "\n",
      "    accuracy                         0.9408     51362\n",
      "   macro avg     0.8824    0.6344    0.7152     51362\n",
      "weighted avg     0.9377    0.9408    0.9345     51362\n",
      "\n",
      "No improvement (2/6)\n",
      "\n",
      "Epoch 26/60\n",
      "Train Loss = 0.2488\n",
      "Val Loss   = 0.2362\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9513    0.9921    0.9713     42759\n",
      "           1     0.8441    0.8849    0.8640      1842\n",
      "           2     0.9124    0.8370    0.8731      1307\n",
      "           3     0.8225    0.5563    0.6637      1341\n",
      "           4     0.8087    0.4221    0.5547       751\n",
      "           5     0.8760    0.8035    0.8382      1837\n",
      "           6     0.8784    0.5058    0.6420       257\n",
      "           7     0.8976    0.3709    0.5249       922\n",
      "           8     0.8750    0.3237    0.4726       346\n",
      "\n",
      "    accuracy                         0.9398     51362\n",
      "   macro avg     0.8740    0.6329    0.7116     51362\n",
      "weighted avg     0.9365    0.9398    0.9330     51362\n",
      "\n",
      "No improvement (3/6)\n",
      "\n",
      "Epoch 27/60\n",
      "Train Loss = 0.2458\n",
      "Val Loss   = 0.2361\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9524    0.9915    0.9716     42759\n",
      "           1     0.8498    0.8817    0.8654      1842\n",
      "           2     0.9118    0.8539    0.8819      1307\n",
      "           3     0.7784    0.6078    0.6826      1341\n",
      "           4     0.8244    0.3875    0.5272       751\n",
      "           5     0.8826    0.7937    0.8358      1837\n",
      "           6     0.8828    0.4981    0.6368       257\n",
      "           7     0.8783    0.3915    0.5416       922\n",
      "           8     0.9444    0.2948    0.4493       346\n",
      "\n",
      "    accuracy                         0.9402     51362\n",
      "   macro avg     0.8783    0.6334    0.7102     51362\n",
      "weighted avg     0.9371    0.9402    0.9337     51362\n",
      "\n",
      "No improvement (4/6)\n",
      "\n",
      "Epoch 28/60\n",
      "Train Loss = 0.2411\n",
      "Val Loss   = 0.2369\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9533    0.9919    0.9722     42759\n",
      "           1     0.8485    0.8882    0.8679      1842\n",
      "           2     0.9234    0.8393    0.8794      1307\n",
      "           3     0.7960    0.5966    0.6820      1341\n",
      "           4     0.8259    0.4168    0.5540       751\n",
      "           5     0.8831    0.7937    0.8360      1837\n",
      "           6     0.8776    0.5019    0.6386       257\n",
      "           7     0.8423    0.4230    0.5632       922\n",
      "           8     0.9636    0.3064    0.4649       346\n",
      "\n",
      "    accuracy                         0.9412     51362\n",
      "   macro avg     0.8793    0.6397    0.7176     51362\n",
      "weighted avg     0.9380    0.9412    0.9351     51362\n",
      "\n",
      "No improvement (5/6)\n",
      "\n",
      "Epoch 29/60\n",
      "Train Loss = 0.2347\n",
      "Val Loss   = 0.2415\n",
      "Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9527    0.9920    0.9720     42759\n",
      "           1     0.8634    0.8713    0.8673      1842\n",
      "           2     0.9043    0.8607    0.8820      1307\n",
      "           3     0.7901    0.6063    0.6861      1341\n",
      "           4     0.7720    0.4328    0.5546       751\n",
      "           5     0.8883    0.7970    0.8402      1837\n",
      "           6     0.9426    0.4475    0.6069       257\n",
      "           7     0.8792    0.3948    0.5449       922\n",
      "           8     0.9519    0.2861    0.4400       346\n",
      "\n",
      "    accuracy                         0.9409     51362\n",
      "   macro avg     0.8827    0.6320    0.7104     51362\n",
      "weighted avg     0.9377    0.9409    0.9346     51362\n",
      "\n",
      "No improvement (6/6)\n",
      "Early stopping triggered\n"
     ]
    }
   ],
   "source": [
    "model = FFNTagger(embedding_matrix, WINDOW, HIDDEN_DIM, NUM_CLASSES).to(DEVICE)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer,\n",
    "    mode='min',\n",
    "    factor=0.5,       \n",
    "    patience=3,       \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "best_val_loss = float(\"inf\")\n",
    "\n",
    "\n",
    "patience_limit = 6\n",
    "patience_counter = 0\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "\n",
    "    model.train()\n",
    "    total_train = 0\n",
    "\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(DEVICE), y.to(DEVICE)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(x)\n",
    "        loss = loss_fn(logits, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_train += loss.item()\n",
    "\n",
    "    avg_train_loss = total_train / len(train_loader)\n",
    "    avg_val_loss, val_report = evaluate(model, val_loader, loss_fn)\n",
    "\n",
    "    \n",
    "    scheduler.step(avg_val_loss)\n",
    "\n",
    "    print(f\"\\nEpoch {epoch}/{EPOCHS}\")\n",
    "    print(f\"Train Loss = {avg_train_loss:.4f}\")\n",
    "    print(f\"Val Loss   = {avg_val_loss:.4f}\")\n",
    "    print(\"Validation Report:\")\n",
    "    print(val_report)\n",
    "\n",
    "    if avg_val_loss < best_val_loss:\n",
    "        best_val_loss = avg_val_loss\n",
    "        patience_counter = 0                     \n",
    "        torch.save(model.state_dict(), \"best_ffn_model.pt\")\n",
    "        print(\" Saved best model!\")\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        print(f\"No improvement ({patience_counter}/{patience_limit})\")\n",
    "\n",
    "    # --- Early stopping break ---\n",
    "    if patience_counter >= patience_limit:\n",
    "        print(\"Early stopping triggered\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL TEST EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-18T15:05:06.245615Z",
     "iopub.status.busy": "2025-11-18T15:05:06.245024Z",
     "iopub.status.idle": "2025-11-18T15:05:07.011702Z",
     "shell.execute_reply": "2025-11-18T15:05:07.011000Z",
     "shell.execute_reply.started": "2025-11-18T15:05:06.245594Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading best model...\n",
      "\n",
      "======== FINAL TEST RESULTS ========\n",
      "Test Loss = 0.2588199995504307\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9497    0.9877    0.9683     38323\n",
      "           1     0.7897    0.8312    0.8099      1617\n",
      "           2     0.8669    0.8227    0.8442      1156\n",
      "           3     0.7715    0.5611    0.6497      1661\n",
      "           4     0.7602    0.4707    0.5814       835\n",
      "           5     0.8550    0.7494    0.7987      1668\n",
      "           6     0.8489    0.4591    0.5960       257\n",
      "           7     0.7343    0.3504    0.4744       702\n",
      "           8     0.7563    0.4167    0.5373       216\n",
      "\n",
      "    accuracy                         0.9298     46435\n",
      "   macro avg     0.8147    0.6277    0.6955     46435\n",
      "weighted avg     0.9241    0.9298    0.9237     46435\n",
      "\n",
      "====================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nLoading best model...\")\n",
    "model.load_state_dict(torch.load(\"best_ffn_model.pt\"))\n",
    "model.to(DEVICE)\n",
    "\n",
    "test_loss, test_report = evaluate(model, test_loader, loss_fn)\n",
    "\n",
    "print(\"\\n======== FINAL TEST RESULTS ========\")\n",
    "print(\"Test Loss =\", test_loss)\n",
    "print(test_report)\n",
    "print(\"====================================\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8764208,
     "sourceId": 13770549,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31193,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
